{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from Statistics import Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "SEED = 9\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP500_df = pd.read_csv('bloombergData/SPXconst.csv')\n",
    "all_companies = list(set(SP500_df.values.flatten()))\n",
    "all_companies.remove(np.nan)\n",
    "\n",
    "constituents = {'-'.join(col.split('/')[::-1]):set(SP500_df[col].dropna()) \n",
    "                for col in SP500_df.columns}\n",
    "\n",
    "constituents_train = {} \n",
    "for test_year in range(1993,2016):\n",
    "    months = [str(t)+'-0'+str(m) if m<10 else str(t)+'-'+str(m) \n",
    "              for t in range(test_year-3,test_year) for m in range(1,13)]\n",
    "    constituents_train[test_year] = [list(constituents[m]) for m in months]\n",
    "    constituents_train[test_year] = set([i for sublist in constituents_train[test_year] \n",
    "                                         for i in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(train_data,test_data):\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    \n",
    "    train_x,train_y = train_data[:,2:-2],train_data[:,-1]\n",
    "    train_y = train_y.astype('int')\n",
    "\n",
    "    print('Started training')\n",
    "    clf = RandomForestClassifier(n_estimators=1000, max_depth=20, random_state = SEED, n_jobs=-1)\n",
    "    clf.fit(train_x,train_y)\n",
    "    print('Completed ',clf.score(train_x,train_y))\n",
    "\n",
    "    dates = list(set(test_data[:,0]))\n",
    "    predictions = {}\n",
    "    for day in dates:\n",
    "        test_d = test_data[test_data[:,0]==day]\n",
    "        test_d = test_d[:,2:-2] \n",
    "        predictions[day] = clf.predict_proba(test_d)[:,1]\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def simulate(test_data,predictions):\n",
    "    rets = pd.DataFrame([],columns=['Long','Short'])\n",
    "    k = 10\n",
    "    for day in sorted(predictions.keys()):\n",
    "        preds = predictions[day]\n",
    "        test_returns = test_data[test_data[:,0]==day][:,-2]\n",
    "        top_preds = predictions[day].argsort()[-k:][::-1] \n",
    "        trans_long = test_returns[top_preds]\n",
    "        worst_preds = predictions[day].argsort()[:k][::-1] \n",
    "        trans_short = -test_returns[worst_preds]\n",
    "        rets.loc[day] = [np.mean(trans_long),np.mean(trans_short)] \n",
    "    return rets   \n",
    "    \n",
    "def create_label(df_open,df_close,perc=[0.5,0.5]):\n",
    "    if not np.all(df_close.iloc[:,0]==df_open.iloc[:,0]):\n",
    "        print('Date Index issue')\n",
    "        return\n",
    "    perc = [0.]+list(np.cumsum(perc))\n",
    "    label = (df_close.iloc[:,1:]/df_open.iloc[:,1:]-1).apply(\n",
    "            lambda x: pd.qcut(x.rank(method='first'),perc,labels=False), axis=1)\n",
    "    return label\n",
    "\n",
    "def create_stock_data(df_close,df_open,st):\n",
    "    st_data = pd.DataFrame([])\n",
    "    st_data['Date'] = list(df_close['Date'])\n",
    "    st_data['Name'] = [st]*len(st_data)\n",
    "    \n",
    "    daily_change = df_close[st]/df_open[st]-1\n",
    "    m = list(range(1,20))+list(range(20,241,20))\n",
    "    for k in m:\n",
    "        st_data['IntraR'+str(k)] = daily_change.shift(k)\n",
    "    for k in m:\n",
    "        st_data['CloseR'+str(k)] = df_close[st].pct_change(k).shift(1)\n",
    "    for k in m:\n",
    "        st_data['OverNR'+str(k)] = df_open[st]/df_close[st].shift(k)-1\n",
    "        \n",
    "    st_data['R-future'] = daily_change \n",
    "    st_data['label'] = list(label[st]) \n",
    "    st_data['Month'] = list(df_close['Date'].str[:-3])\n",
    "    st_data = st_data.dropna()\n",
    "    \n",
    "    trade_year = st_data['Month'].str[:4]\n",
    "    st_data = st_data.drop(columns=['Month'])\n",
    "    st_train_data = st_data[trade_year<str(test_year)]\n",
    "    st_test_data = st_data[trade_year==str(test_year)]\n",
    "    return np.array(st_train_data),np.array(st_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "1993\n",
      "----------------------------------------\n",
      "Created : (253361, 97) (125156, 97) 61.011282205581665\n",
      "Started training\n",
      "Completed  0.9793377828473996\n",
      "Mean \t\t 0.006150128107253382\n",
      "Standard dev \t 0.009698902082497227\n",
      "Sharpe ratio \t 9.5750945692667\n",
      "----------------------------------------\n",
      "1994\n",
      "----------------------------------------\n",
      "Created : (252354, 97) (124243, 97) 60.74263572692871\n",
      "Started training\n",
      "Completed  0.9744525547445255\n",
      "Mean \t\t 0.007272098713459108\n",
      "Standard dev \t 0.008193822815745492\n",
      "Sharpe ratio \t 13.507570075759237\n",
      "----------------------------------------\n",
      "1995\n",
      "----------------------------------------\n",
      "Created : (250600, 97) (123277, 97) 60.39605259895325\n",
      "Started training\n",
      "Completed  0.9779728651237031\n",
      "Mean \t\t 0.006039228127439897\n",
      "Standard dev \t 0.009891978246386357\n",
      "Sharpe ratio \t 9.210232754941591\n",
      "----------------------------------------\n",
      "1996\n",
      "----------------------------------------\n",
      "Created : (242919, 97) (122662, 97) 60.52493977546692\n",
      "Started training\n",
      "Completed  0.9748805157274647\n",
      "Mean \t\t 0.005408536618238995\n",
      "Standard dev \t 0.00887307190843005\n",
      "Sharpe ratio \t 9.139507215637153\n",
      "----------------------------------------\n",
      "1997\n",
      "----------------------------------------\n",
      "Created : (246446, 97) (122150, 97) 60.74020528793335\n",
      "Started training\n",
      "Completed  0.9592892560642088\n",
      "Mean \t\t 0.007108412220824769\n",
      "Standard dev \t 0.00978678594025932\n",
      "Sharpe ratio \t 11.043481896593734\n",
      "----------------------------------------\n",
      "1998\n",
      "----------------------------------------\n",
      "Created : (248758, 97) (120617, 97) 60.71569538116455\n",
      "Started training\n",
      "Completed  0.9645076741250532\n",
      "Mean \t\t 0.007572189995246863\n",
      "Standard dev \t 0.011932280723795626\n",
      "Sharpe ratio \t 9.674800648562785\n",
      "----------------------------------------\n",
      "1999\n",
      "----------------------------------------\n",
      "Created : (248056, 97) (120021, 97) 60.479010343551636\n",
      "Started training\n",
      "Completed  0.9664067791143935\n",
      "Mean \t\t 0.006915934585783437\n",
      "Standard dev \t 0.015276014476161667\n",
      "Sharpe ratio \t 6.8751378698558065\n",
      "----------------------------------------\n",
      "2000\n",
      "----------------------------------------\n",
      "Created : (247675, 97) (121390, 97) 60.863526344299316\n",
      "Started training\n",
      "Completed  0.9550741899666902\n",
      "Mean \t\t 0.012604944334960696\n",
      "Standard dev \t 0.017299525366287375\n",
      "Sharpe ratio \t 11.291346525694593\n",
      "----------------------------------------\n",
      "2001\n",
      "----------------------------------------\n",
      "Created : (247139, 97) (119614, 97) 60.784218549728394\n",
      "Started training\n",
      "Completed  0.9595005239966173\n",
      "Mean \t\t 0.007622649495813286\n",
      "Standard dev \t 0.024142797263945737\n",
      "Sharpe ratio \t 4.81482968825994\n",
      "----------------------------------------\n",
      "2002\n",
      "----------------------------------------\n",
      "Created : (247923, 97) (123412, 97) 68.96894001960754\n",
      "Started training\n",
      "Completed  0.9643074664311096\n",
      "Mean \t\t 0.008325318666250893\n",
      "Standard dev \t 0.02070174875199421\n",
      "Sharpe ratio \t 6.153972102738146\n",
      "----------------------------------------\n",
      "2003\n",
      "----------------------------------------\n",
      "Created : (248888, 97) (124315, 97) 70.07841682434082\n",
      "Started training\n",
      "Completed  0.9683632798688566\n",
      "Mean \t\t 0.0034298789475301662\n",
      "Standard dev \t 0.010745304610140357\n",
      "Sharpe ratio \t 4.623906885480038\n",
      "----------------------------------------\n",
      "2004\n",
      "----------------------------------------\n",
      "Created : (252587, 97) (124285, 97) 69.83271312713623\n",
      "Started training\n",
      "Completed  0.9736288882642417\n",
      "Mean \t\t 0.004540961107878856\n",
      "Standard dev \t 0.009792543045115882\n",
      "Sharpe ratio \t 6.8749425106325734\n",
      "----------------------------------------\n",
      "2005\n",
      "----------------------------------------\n",
      "Created : (255324, 97) (124015, 97) 65.06134796142578\n",
      "Started training\n",
      "Completed  0.975168805126036\n",
      "Mean \t\t 0.0037441099976802924\n",
      "Standard dev \t 0.008509014948904828\n",
      "Sharpe ratio \t 6.425367869158189\n",
      "----------------------------------------\n",
      "2006\n",
      "----------------------------------------\n",
      "Created : (254596, 97) (121379, 97) 67.17542839050293\n",
      "Started training\n",
      "Completed  0.9819910760577543\n",
      "Mean \t\t 0.0028454887248346643\n",
      "Standard dev \t 0.009261781644884106\n",
      "Sharpe ratio \t 4.362916589434916\n",
      "----------------------------------------\n",
      "2007\n",
      "----------------------------------------\n",
      "Created : (251639, 97) (120727, 97) 70.44354915618896\n",
      "Started training\n",
      "Completed  0.9784492864778512\n",
      "Mean \t\t 0.0030870517646057255\n",
      "Standard dev \t 0.007983358063573448\n",
      "Sharpe ratio \t 5.541912915460432\n",
      "----------------------------------------\n",
      "2008\n",
      "----------------------------------------\n",
      "Created : (249229, 97) (122931, 97) 69.37865352630615\n",
      "Started training\n",
      "Completed  0.9705130622840841\n",
      "Mean \t\t 0.0030740479874416665\n",
      "Standard dev \t 0.02463999294218856\n",
      "Sharpe ratio \t 1.7872020784137397\n",
      "----------------------------------------\n",
      "2009\n",
      "----------------------------------------\n",
      "Created : (249849, 97) (122143, 97) 69.9613106250763\n",
      "Started training\n",
      "Completed  0.9646626562443716\n",
      "Mean \t\t 0.002685025107674097\n",
      "Standard dev \t 0.02111285748259909\n",
      "Sharpe ratio \t 1.7932721738167756\n",
      "----------------------------------------\n",
      "2010\n",
      "----------------------------------------\n",
      "Created : (249783, 97) (122599, 97) 65.17692494392395\n",
      "Started training\n",
      "Completed  0.9430385574678821\n",
      "Mean \t\t 0.002892908753306355\n",
      "Standard dev \t 0.010057511003748267\n",
      "Sharpe ratio \t 4.092578212029475\n",
      "----------------------------------------\n",
      "2011\n",
      "----------------------------------------\n",
      "Created : (251982, 97) (124081, 97) 65.20731902122498\n",
      "Started training\n",
      "Completed  0.9227286075989555\n",
      "Mean \t\t 0.002815274499558731\n",
      "Standard dev \t 0.010756090668480715\n",
      "Sharpe ratio \t 3.712198610074469\n",
      "----------------------------------------\n",
      "2012\n",
      "----------------------------------------\n",
      "Created : (252331, 97) (121638, 97) 87.12644267082214\n",
      "Started training\n",
      "Completed  0.9586178471927745\n",
      "Mean \t\t 0.002787254916679708\n",
      "Standard dev \t 0.009561202859820346\n",
      "Sharpe ratio \t 4.129600461304826\n",
      "----------------------------------------\n",
      "2013\n",
      "----------------------------------------\n",
      "Created : (248275, 97) (123676, 97) 80.37595105171204\n",
      "Started training\n",
      "Completed  0.9650629342462995\n",
      "Mean \t\t 0.0025832459824324298\n",
      "Standard dev \t 0.007507057479768956\n",
      "Sharpe ratio \t 4.828177539162374\n",
      "----------------------------------------\n",
      "2014\n",
      "----------------------------------------\n",
      "Created : (247231, 97) (124571, 97) 80.59525418281555\n",
      "Started training\n",
      "Completed  0.9797921781653596\n",
      "Mean \t\t 0.0014626294875964704\n",
      "Standard dev \t 0.008269802307534926\n",
      "Sharpe ratio \t 2.2317547941536864\n",
      "----------------------------------------\n",
      "2015\n",
      "----------------------------------------\n",
      "Created : (252552, 97) (123832, 97) 84.55573725700378\n",
      "Started training\n",
      "Completed  0.9759059520415597\n",
      "Mean \t\t 0.0028142776801640865\n",
      "Standard dev \t 0.01022889124044135\n",
      "Sharpe ratio \t 3.9019791953839644\n",
      "----------------------------------------\n",
      "2016\n",
      "----------------------------------------\n",
      "Created : (252110, 97) (121792, 97) 77.31285810470581\n",
      "Started training\n",
      "Completed  0.9683709491888461\n",
      "Mean \t\t 0.0011776559405672633\n",
      "Standard dev \t 0.009130111889437395\n",
      "Sharpe ratio \t 1.5259786847338739\n",
      "----------------------------------------\n",
      "2017\n",
      "----------------------------------------\n",
      "Created : (252455, 97) (123884, 97) 70.22024178504944\n",
      "Started training\n",
      "Completed  0.9894991186548098\n",
      "Mean \t\t 0.0015229921152470141\n",
      "Standard dev \t 0.00813099277396593\n",
      "Sharpe ratio \t 2.3877032600717962\n",
      "----------------------------------------\n",
      "2018\n",
      "----------------------------------------\n",
      "Created : (252741, 97) (122924, 97) 77.55966424942017\n",
      "Started training\n",
      "Completed  0.9877542622684883\n",
      "Mean \t\t 0.0010542352504608493\n",
      "Standard dev \t 0.009273674774139108\n",
      "Sharpe ratio \t 1.291086188393858\n",
      "----------------------------------------\n",
      "2019\n",
      "----------------------------------------\n",
      "Created : (254258, 97) (114586, 97) 74.33531546592712\n",
      "Started training\n",
      "Completed  0.98131032258572\n"
     ]
    }
   ],
   "source": [
    "result_folder = 'results1'\n",
    "\n",
    "for test_year in range(1993,2020):\n",
    "    \n",
    "    print('-'*40)\n",
    "    print(test_year)\n",
    "    print('-'*40)\n",
    "    \n",
    "    filename = 'bloombergData/Open-'+str(test_year-3)+'.csv'\n",
    "    df_open = pd.read_csv(filename)\n",
    "    filename = 'bloombergData/Close-'+str(test_year-3)+'.csv'\n",
    "    df_close = pd.read_csv(filename)\n",
    "    \n",
    "    label = create_label(df_open,df_close)\n",
    "    stock_names = sorted(list(constituents[str(test_year-1)+'-12']))\n",
    "    train_data,test_data = [],[]\n",
    "    \n",
    "    start = time.time()\n",
    "    for st in stock_names:\n",
    "        st_train_data,st_test_data = create_stock_data(df_close,df_open,st)\n",
    "        train_data.append(st_train_data)\n",
    "        test_data.append(st_test_data)\n",
    "\n",
    "    train_data = np.concatenate([x for x in train_data])\n",
    "    test_data = np.concatenate([x for x in test_data])\n",
    "    \n",
    "    print('Created :',train_data.shape,test_data.shape,time.time()-start)\n",
    "    \n",
    "    predictions = trainer(train_data,test_data)\n",
    "    returns = simulate(test_data,predictions)\n",
    "    result = Statistics(returns.sum(axis=1))\n",
    "    result.shortreport() \n",
    "    \n",
    "    with open(result_folder+'/predictions-'+str(test_year)+'.pickle', 'wb') as handle:\n",
    "        pickle.dump(predictions, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    returns.to_csv(result_folder+'/avg_daily_rets-'+str(test_year)+'.csv')\n",
    "    with open(result_folder+\"/avg_returns.txt\", \"a\") as myfile:\n",
    "        res = '-'*30 + '\\n' \n",
    "        res += str(test_year) + '\\n'\n",
    "        res += 'Mean = ' + str(result.mean()) + '\\n'\n",
    "        res += 'Sharpe = '+str(result.sharpe()) + '\\n'\n",
    "        res += '-'*30 + '\\n'\n",
    "        myfile.write(res)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
